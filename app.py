import streamlit as st
from konlpy.tag import Komoran
from collections import Counter
import mylib.myTextMining as tm
import mylib.NaverNewsCrawler as nnc
import pandas as pd
import os

uploaded_file = st.sidebar.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

col_name = st.sidebar.text_input("ë°ì´í„°ê°€ ìˆëŠ” ì»¬ëŸ¼ëª…", value="review")
check_col_button = st.sidebar.button("ë°ì´í„° íŒŒì¼ í™•ì¸")

df = None

if check_col_button:
    try:
        df = pd.read_csv(uploaded_file)
        if col_name in df.columns:
            st.sidebar.success(f"'{col_name}' ì»¬ëŸ¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤!")
            st.session_state["valid_column"] = True
        else:
            st.sidebar.error(f"'{col_name}' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.session_state["valid_column"] = False
    except Exception as e:
        st.sidebar.error(f"CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.session_state["valid_column"] = False

st.sidebar.header("ì„¤ì •")

show_bar = st.sidebar.checkbox("ë¹ˆë„ìˆ˜ ê·¸ë˜í”„", value=True)
bar_count = st.sidebar.slider("ë‹¨ì–´ ìˆ˜", 10, 50, 20)

show_wc = st.sidebar.checkbox("ì›Œë“œí´ë¼ìš°ë“œ", value=True)
wc_count = st.sidebar.slider("ë‹¨ì–´ ìˆ˜", 20, 500, 50)

start_analysis = st.sidebar.button("ğŸ” ë¶„ì„ ì‹œì‘")

os.makedirs("./data", exist_ok=True)

# ======== ë¶„ì„ ë¡œì§ ========
if start_analysis:
    st.info("ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. corpus ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    if uploaded_file is not None:
        st.success("ì—…ë¡œë“œí•œ CSV íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
        df = pd.read_csv(uploaded_file)
        corpus_list = df["description"].dropna().tolist()

    # 2. í˜•íƒœì†Œ ë¶„ì„ ì„¤ì •
    tokenizer = Komoran().pos
    tags = ['NNG', 'NNP', 'VV', 'VA']
    stopwords = ['í•˜ë©°', 'ì…', 'í•˜ê³ ', 'ë¡œì¨', 'í•˜ì—¬', 'ì• ', 'ì œ', 'ê·¸', 'ì´', 'í•˜', 'ìˆ', 'ë°›', 'ì˜í™”', 'ê²ƒ',
                 'ê²€ìƒ‰', 'ë‹¨ì–´', 'í†µí•˜', 'ì˜ì–´', 'ì •ë³´', 'ë³´', 'ë§', 'ì¸í„°ë„·', 'ì‚¬ìš©', 'ëœ»', 'ë˜', 'ìœ„í•˜', 'ë”°ë¥´']

    # 3. ë¹ˆë„ ë¶„ì„
    counter = tm.analyze_word_freq(corpus_list, tokenizer, tags, stopwords)

    # 4. ì‹œê°í™” ì¶œë ¥
    if show_bar:
        st.subheader(" í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ê·¸ë˜í”„")
        tm.visualize_barchart(counter, "ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„", "ë¹ˆë„ìˆ˜", "í‚¤ì›Œë“œ", max_words=bar_count)

    if show_wc:
        st.subheader(" ì›Œë“œí´ë¼ìš°ë“œ")
        tm.visualize_wordcloud(counter, max_words=wc_count)
        
from mylib.metacritic_crawler import crawl_game_reviews
from mylib.sentiment_analyzer import analyze_sentiment

st.title("ğŸ® Metacritic ë¦¬ë·° ê°ì„± ë¶„ì„ê¸°")

url = st.text_input("Metacritic ë¦¬ë·° í˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”", 
                    value="https://www.metacritic.com/game/elden-ring/user-reviews")
num_pages = st.slider("í˜ì´ì§€ ìˆ˜", 1, 10, 3)

if st.button("í¬ë¡¤ë§ ë° ë¶„ì„ ì‹œì‘"):
    with st.spinner("ë¦¬ë·° í¬ë¡¤ë§ ì¤‘..."):
        try:
            df = crawl_game_reviews(url, num_pages=num_pages)
            st.success(f"{len(df)}ê°œì˜ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ")

            df = analyze_sentiment(df)  # â­ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
            st.success("ê°ì„± ë¶„ì„ ì™„ë£Œ")

            st.bar_chart(df["ê°ì •ë¶„ë¥˜"].value_counts())
            st.dataframe(df)

            csv = df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ", csv, file_name="sentiment_reviews.csv")

        except Exception as e:
            st.error(str(e))